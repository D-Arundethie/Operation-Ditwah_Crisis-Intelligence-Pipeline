{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b9961e5",
   "metadata": {},
   "source": [
    "### Part 3: The Logistics Commander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976f0896",
   "metadata": {},
   "source": [
    "##### *Import Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d9ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.prompts import render\n",
    "from utils.llm_client import LLMClient\n",
    "from utils.router import pick_model\n",
    "from utils.logging_utils import log_llm_call\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158b2be4",
   "metadata": {},
   "source": [
    "##### *Load data  from incidents.txt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "222ea92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 incidents loaded\n"
     ]
    }
   ],
   "source": [
    "input_path = '../data/incidents.txt'\n",
    "\n",
    "try:\n",
    "    with open(input_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        headers = lines[0].strip()\n",
    "        incidents = [line.strip() for line in lines[1:] if line.strip()]\n",
    "    print(f\"{len(incidents)} incidents loaded\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found\")\n",
    "    scenarios = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eabbdcf",
   "metadata": {},
   "source": [
    "##### *Setup LLM Client*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4ec69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pick_model('openai', 'general')\n",
    "client = LLMClient('openai', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f7c9c2",
   "metadata": {},
   "source": [
    "##### *Step A: CoT Scoring*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f497ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident: 1  | 08:00 AM| Gampaha | 4      | 20-40  | Water     | \"Thirsty but safe on roof. Water level stable.\"\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Result: \n",
      "1. Identify the components of the row: \n",
      "   - Time: 08:00 AM\n",
      "   - Location: Gampaha\n",
      "   - Severity Level: 4\n",
      "   - Age Group: 20-40\n",
      "   - Need: Water\n",
      "   - Situation: \"Thirsty but safe on roof. Water level stable.\"\n",
      "\n",
      "2. Determine the priority score based on the severity level and situation:\n",
      "   - Severity Level: 4 indicates a moderate level of urgency.\n",
      "   - The individual is \"thirsty but safe,\" which suggests that while they need water, they are not in immediate danger.\n",
      "   - The water level being stable indicates no immediate threat to life.\n",
      "\n",
      "3. Assign a score based on the above factors:\n",
      "   - Severity Level: 4 contributes a score of 4.\n",
      "   - Safety status (safe on roof) suggests a lower urgency, potentially reducing the score.\n",
      "   - Need for water is important but not life-threatening at this moment.\n",
      "\n",
      "4. Calculate the final priority score:\n",
      "   - Given the factors, the score remains at 4, as the need for water is significant but the safety status mitigates the urgency.\n",
      "\n",
      "Answer: 4\n",
      "Score: 4/10\n",
      "Incident: 2  | 08:15 AM| Ja-Ela  | 1      | 75     | Insulin   | \"Diabetic, missed dose yesterday. Feeling faint.\"\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Result: \n",
      "1. Identify the key factors in the provided data: \n",
      "   - Time: 08:15 AM\n",
      "   - Location: Ja-Ela\n",
      "   - Severity Level: 1 (indicating a low severity)\n",
      "   - Vital Signs: 75 (likely indicating blood sugar level)\n",
      "   - Medication: Insulin\n",
      "   - Patient Condition: \"Diabetic, missed dose yesterday. Feeling faint.\"\n",
      "\n",
      "2. Assess the urgency based on the patient's condition:\n",
      "   - The patient is diabetic and has missed a dose of insulin, which can lead to complications.\n",
      "   - The symptom \"feeling faint\" indicates a potential hypoglycemic episode, which is concerning.\n",
      "\n",
      "3. Determine the priority score:\n",
      "   - Severity Level: 1 (low)\n",
      "   - However, the missed insulin dose and faintness elevate the urgency despite the low severity score.\n",
      "   - Assign a higher priority due to the risk of acute complications from diabetes.\n",
      "\n",
      "4. Finalize the priority score based on the assessment:\n",
      "   - Given the context, the priority score should reflect the need for timely intervention despite the initial severity level.\n",
      "\n",
      "Answer: 3\n",
      "Score: 3/10\n",
      "Incident: 3  | 08:20 AM| Ragama  | 2      | 10, 35 | Rescue    | \"Water approaching neck level. Child is crying.\"\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Result: \n",
      "1. **Identify the components of the row**: \n",
      "   - Time: 08:20 AM\n",
      "   - Location: Ragama\n",
      "   - Severity Level: 2\n",
      "   - Additional Information: \"Water approaching neck level. Child is crying.\"\n",
      "   - Type of Incident: Rescue\n",
      "\n",
      "2. **Assess the severity**: \n",
      "   - Severity Level 2 indicates a moderate level of urgency.\n",
      "\n",
      "3. **Evaluate the situation**: \n",
      "   - The description indicates a child in distress due to rising water, which is a critical situation.\n",
      "\n",
      "4. **Determine the priority score**: \n",
      "   - Given the severity level and the critical nature of the situation (child in water), the priority score should be high.\n",
      "\n",
      "5. **Assign a score**: \n",
      "   - Based on the urgency of the situation, I would assign a priority score of 8 out of 10.\n",
      "\n",
      "Answer: 8\n",
      "Score: 8/10\n"
     ]
    }
   ],
   "source": [
    "scored_results = []\n",
    "\n",
    "scoring_rules = \"\"\"\n",
    "Analyze the incident and calculate a score (0-10) strictly using these rules:\n",
    "    - Start with Base Score: 5\n",
    "    - Check the 'Ages' column. If ANY age is > 60 OR < 5, add +2.\n",
    "    - Check 'Main_Need' and 'Message'; \n",
    "            - If 'Rescue' or 'Flood' or life threat add +3.\n",
    "            - If 'Insulin' or 'Medicine' add +1.\n",
    "    - Max Score is 10.\n",
    "    - Output Format: \"Score: Number/10\".\n",
    "\"\"\"\n",
    "\n",
    "for incident in incidents:\n",
    "    prompt_text, spec = render(\n",
    "                                'cot_reasoning.v1',\n",
    "                                role='Triage Officer',\n",
    "                                problem=f\"Calculate priority score for this row: {incident}\",\n",
    "                                context=f\"Headers: {headers}\\n\\nRules:\\n{scoring_rules}\",\n",
    "                                format=\"Final Answer: Score: [Number]/10\"\n",
    "                            )\n",
    "\n",
    "    response = client.chat([{'role': 'user', 'content': prompt_text}], temperature=0.0)\n",
    "    output = response['text'].strip()\n",
    "\n",
    "    match = re.search(r\"(?:Score|Answer):\\s*(\\d+)\", output)\n",
    "    if match:\n",
    "        final_score = match.group(1)\n",
    "        final_score_str = f\"Score: {final_score}/10\"\n",
    "    else:\n",
    "        final_score_str = \"Score: ?/10\"\n",
    "    \n",
    "    scored_results.append(f\"Incident: {incident} | {output} | {final_score_str}\")\n",
    "    \n",
    "    print(f\"Incident: {incident}\")\n",
    "    print(f\"{'-'*150}\")\n",
    "    print(f\"Result: \\n{output}\")\n",
    "    print(f\"{final_score_str}\")\n",
    "    log_llm_call('openai', model, 'cot_scoring', response['latency_ms'], response['usage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac626ee",
   "metadata": {},
   "source": [
    "##### *Step B: ToT Strategy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ab37726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Route:\n",
      "\n",
      "To solve the problem of prioritizing incidents while maximizing the total priority score and minimizing time, let's explore the three distinct solution paths: Greedy, Speed, and Logistics.\n",
      "\n",
      "### Branch 1: Greedy Approach\n",
      "**Hypothesis:** The best strategy is to attend to the incident with the highest priority score first.\n",
      "\n",
      "**Steps:**\n",
      "1. **Identify the scores for each incident:**\n",
      "   - Incident 1 (Gampaha): Score 4\n",
      "   - Incident 2 (Ja-Ela): Score 3\n",
      "   - Incident 3 (Ragama): Score 8\n",
      "2. **Order the incidents by score:**\n",
      "   - 1st: Incident 3 (Ragama, Score 8)\n",
      "   - 2nd: Incident 1 (Gampaha, Score 4)\n",
      "   - 3rd: Incident 2 (Ja-Ela, Score 3)\n",
      "3. **Plan the route:**\n",
      "   - Start at Ragama (08:20 AM incident).\n",
      "   - Move to Gampaha (08:00 AM incident).\n",
      "   - Finally, head to Ja-Ela (08:15 AM incident).\n",
      "\n",
      "**Intermediate Check:**\n",
      "- Total Priority Score: 8 + 4 + 3 = 15\n",
      "- Total Time Taken: 08:20 AM (Ragama) → 08:00 AM (Gampaha) → 08:15 AM (Ja-Ela)\n",
      "\n",
      "### Branch 2: Speed Approach\n",
      "**Hypothesis:** The best strategy is to attend to the incident that is closest in terms of time and location first.\n",
      "\n",
      "**Steps:**\n",
      "1. **Identify the locations and times:**\n",
      "   - Incident 1 (Gampaha): 08:00 AM\n",
      "   - Incident 2 (Ja-Ela): 08:15 AM\n",
      "   - Incident 3 (Ragama): 08:20 AM\n",
      "2. **Order the incidents by proximity (time):**\n",
      "   - 1st: Incident 1 (Gampaha, 08:00 AM)\n",
      "   - 2nd: Incident 2 (Ja-Ela, 08:15 AM)\n",
      "   - 3rd: Incident 3 (Ragama, 08:20 AM)\n",
      "3. **Plan the route:**\n",
      "   - Start at Gampaha (08:00 AM incident).\n",
      "   - Move to Ja-Ela (08:15 AM incident).\n",
      "   - Finally, head to Ragama (08:20 AM incident).\n",
      "\n",
      "**Intermediate Check:**\n",
      "- Total Priority Score: 4 + 3 + 8 = 15\n",
      "- Total Time Taken: 08:00 AM (Gampaha) → 08:15 AM (Ja-Ela) → 08:20 AM (Ragama)\n",
      "\n",
      "### Branch 3: Logistics Approach\n",
      "**Hypothesis:** The best strategy is to follow a predetermined route starting from Ragama.\n",
      "\n",
      "**Steps:**\n",
      "1. **Start from Ragama (08:20 AM incident).**\n",
      "2. **Plan the route:**\n",
      "   - First, handle the incident in Gampaha (08:00 AM).\n",
      "   - Next, move to Ja-Ela (08:15 AM incident).\n",
      "3. **Order the incidents:**\n",
      "   - 1st: Incident 1 (Gampaha, Score 4)\n",
      "   - 2nd: Incident 2 (Ja-Ela, Score 3)\n",
      "   - 3rd: Incident 3 (Ragama, Score 8)\n",
      "\n",
      "**Intermediate Check:**\n",
      "- Total Priority Score: 4 + 3 + 8 = 15\n",
      "- Total Time Taken: 08:20 AM (Ragama) → 08:00 AM (Gampaha) → 08:15 AM (Ja-Ela)\n",
      "\n",
      "### Conclusion\n",
      "After analyzing all three branches, the total priority score remains the same at 15 for each path. However, the time taken is shortest in Branch 2 (Speed) because it prioritizes the incident that occurs first in time (Gampaha at 08:00 AM) and ensures that all incidents are attended to in the order they occur.\n",
      "\n",
      "**Final Answer:** The best path is Branch 2 (Speed): Go to the closest location first, with a total priority score of 15.\n"
     ]
    }
   ],
   "source": [
    "incidents_data = \"\\n\".join(scored_results)\n",
    "\n",
    "problem = f\"\"\"\n",
    "                You are the Logistics Commander at Ragama (Starting Point).\n",
    "                Incidents to attend (with scores): {incidents_data}\n",
    "\n",
    "                Task: Compare these 3 branches and select the best route to maximize Total Priority Score saved in minimum time.\n",
    "                Branch 1 (Greedy): Go to the incident with the Highest Score first.\n",
    "                Branch 2 (Speed): Go to the Closest location first (Ragama/Ja-Ela).\n",
    "                Branch 3 (Logictics): Go to Gampaha first.\n",
    "\n",
    "                Assume the boat has unlimited capacity but must stop at each location to handle the incident.\n",
    "            \"\"\"\n",
    "\n",
    "constraints = f\"\"\" \n",
    "                Travel Constraints:\n",
    "                - Ragama (Start) -> Ragama Incident: 0 mins\n",
    "                - Ragama -> Ja-Ela: 10 mins\n",
    "                - Ja-Ela -> Gampaha: 40 mins\n",
    "                Total Path: Ragama -> Ja-Ela -> Gampaha is 50 mins\n",
    "            \"\"\"\n",
    "\n",
    "prompt_text, spec = render(\n",
    "                            'tot_reasoning.v1',\n",
    "                            role='Logistics Commander',\n",
    "                            problem=problem,\n",
    "                            branches=\"3 (Greedy, Speed, Logictics)\",\n",
    "                            constraints=constraints\n",
    "                        )\n",
    "\n",
    "response_tot = client.chat([{'role': 'user', 'content': prompt_text}], temperature=spec.temperature)\n",
    "\n",
    "print(\"Optimal Route:\\n\")\n",
    "print(response_tot['text'])\n",
    "\n",
    "log_llm_call('openai', model, 'tot_strategy', response_tot['latency_ms'], response_tot['usage'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
