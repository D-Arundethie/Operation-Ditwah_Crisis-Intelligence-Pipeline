{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e1abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('..') \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7786bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.prompts import render\n",
    "from utils.llm_client import LLMClient\n",
    "from utils.router import pick_model\n",
    "from utils.logging_utils import log_llm_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf0bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample messages\n",
    "input_file_path = '../data/Sample Messages.txt'\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    with open(input_file_path, 'r') as f:\n",
    "        messages = [line.strip() for line in f.readlines() if line.strip()]\n",
    "    print(f\"Loaded {len(messages)} messages.\")\n",
    "\n",
    "    print(\"First 5 messages:\")\n",
    "    for msg in messages[:5]:\n",
    "        print(msg)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {input_file_path}\")\n",
    "    messages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796bef35",
   "metadata": {},
   "source": [
    "##### *Setup LLM Client*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c5898",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pick_model(\"openai\", \"general\")\n",
    "llm = LLMClient(\"openai\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1127f9ce",
   "metadata": {},
   "source": [
    "##### *Examples for Rescue, Supply, Info, Other classifications*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = \"\"\"\n",
    "Example 1:\n",
    "        Message: \"We are stuck in our house with rising flood water up to waist level in Hanwella\"\n",
    "        District: Colombo | Intent: Rescue | Priority: High\n",
    "\n",
    "Example 2:\n",
    "        Message: \"Need baby formula and diapers for displaced families at the school shelter\"\n",
    "        District: Kandy | Intent: Supply | Priority: High\n",
    "\n",
    "Example 3:\n",
    "        Message: \"WARNING: Dam at Moragahakanda reservoir is at risk of breaching within the next 2 hours. Immediate evacuation ordered for downstream villages in Kalu Ganga.\"\n",
    "        District: Matale | Intent: Info | Priority: High\n",
    "\n",
    "Example 4:\n",
    "        Message: \"Heart attack patient in Batticaloa needs immediate ambulance. No transport available due to flooding and landsliding.\"\n",
    "        District: Batticaloa | Intent: Other | Priority: High\n",
    "\n",
    "Example 5:\n",
    "        Message: \"Reporting an old landslide blockage in Kelanimulla from previous rains. Not blocking anything urgent\"\n",
    "        District: Colombo | Intent: Rescue | Priority: Low\n",
    "\n",
    "Example 6:\n",
    "        Message: \"Message: For future preparedness along Attanagalu Oya, we need sandbags and tarpaulin sheets for storage.\"\n",
    "        District: Gampaha | Intent: Supply | Priority: Low\n",
    "\n",
    "Example 7:\n",
    "        Message: \"Heavy rains expected to continue for 24 hours\"\n",
    "        District: None | Intent: Info | Priority: Low\n",
    "\n",
    "Example 8:\n",
    "        Message: \"Road from Kandy to Nuwara Eliya is now open after landslide clearance\",\n",
    "        District: None | Intent: Other | Priority: Low\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd39db97",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "print(f\"{'District':<15} | {'Intent':<15} | {'Priority':<10} | {'Message':<50}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for msg in messages:\n",
    "    prompt_text, spec = render(\n",
    "                                'few_shot.v1',\n",
    "                                role='Crisis Intelligence Classifier',\n",
    "                                examples=examples,\n",
    "                                query=f'Message: \"{msg}\"',\n",
    "                                constraints='Classify the message exactly according to the Output format. Do not add extra text.',\n",
    "                                format='District: [Name] | Intent: [Category] | Priority: [High/Low]'\n",
    "                                )\n",
    "\n",
    "    response = llm.chat([{'role': 'user', 'content': prompt_text}], temperature=0.0)\n",
    "    \n",
    "    output_text = response['text'].strip()\n",
    "    \n",
    "    parsed_data = {\n",
    "                    'original_message': msg, \n",
    "                    'raw_output': output_text,\n",
    "                    'district': 'Unknown',\n",
    "                    'intent': 'Unknown',\n",
    "                    'priority': 'Unknown'\n",
    "                    }\n",
    "    \n",
    "    try:\n",
    "        parts = [p.split(':')[1].strip() for p in output_text.split('|')]\n",
    "        if len(parts) == 3:\n",
    "            parsed_data['district'] = parts[0]\n",
    "            parsed_data['intent'] = parts[1]\n",
    "            parsed_data['priority'] = parts[2]\n",
    "    except Exception as e:\n",
    "        print(f\"Parsing error for message '{msg}': {e}\")\n",
    "\n",
    "    results.append(parsed_data)\n",
    "\n",
    "    log_llm_call('openai', model, 'few_shot_classify', response['latency_ms'], response['usage'])\n",
    "    \n",
    "    print(f\"{str(parsed_data['district']):<15} | {str(parsed_data['intent']):<15} | {str(parsed_data['priority']):<10} | {msg[:30]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00415b77",
   "metadata": {},
   "source": [
    "##### *Save to an Excel*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b463f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "output_path = f'{output_dir}/classified_messages.xlsx'\n",
    "\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"\\nClassified messages saved to: {output_path}\")\n",
    "print(df[['original_message', 'intent', 'priority']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fac40ac",
   "metadata": {},
   "source": [
    "##### *Success Check*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c1212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test example 1\n",
    "test_msg1 = 'Breaking News: Kelani River level at 9m.'\n",
    "prompt_text1, _ = render(\n",
    "                        'few_shot.v1',\n",
    "                        role='Crisis message classifier for Sri Lanka DMC',\n",
    "                        examples=examples,\n",
    "                        query=f'Message: {test_msg1}',\n",
    "                        constraints='''\n",
    "                        - Extract district name if explicitly mentioned, else None\n",
    "                        - Intent: Rescue (SOS/help needed), Supply (donations/requests), Info (news/updates), Other (irrelevant/spam)\n",
    "                        - Priority: High for urgent Rescue/Supply, Low otherwise\n",
    "                        - If no district, use None\n",
    "                        ''',\n",
    "                        format='District: [Name] | Intent: [Category] | Priority: [High/Low]'\n",
    "                        )\n",
    "\n",
    "response1 = client.chat([{'role': 'user', 'content': prompt_text1}], temperature=0.0)\n",
    "print('Test 1:', response1['text'])\n",
    "# Expected: District: Colombo | Intent: Info | Priority: Low (note: example has Colombo, but msg doesn't; adjust if needed)\n",
    "\n",
    "# Test example 2\n",
    "test_msg2 = 'We are trapped on the roof with 3 kids!'\n",
    "prompt_text2, _ = render(\n",
    "    'few_shot.v1',\n",
    "    role='Crisis message classifier for Sri Lanka DMC',\n",
    "    examples=examples,\n",
    "    query=f'Message: {test_msg2}',\n",
    "    constraints='''\n",
    "    - Extract district name if explicitly mentioned, else None\n",
    "    - Intent: Rescue (SOS/help needed), Supply (donations/requests), Info (news/updates), Other (irrelevant/spam)\n",
    "    - Priority: High for urgent Rescue/Supply, Low otherwise\n",
    "    - If no district, use None\n",
    "    ''',\n",
    "    format='District: [Name] | Intent: [Category] | Priority: [High/Low]'\n",
    ")\n",
    "\n",
    "response2 = client.chat([{'role': 'user', 'content': prompt_text2}], temperature=0.0)\n",
    "print('Test 2:', response2['text'])\n",
    "# Expected: District: None | Intent: Rescue | Priority: High\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
